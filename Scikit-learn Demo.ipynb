{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A python library for machine learning.\n",
    "\n",
    "Some things you can do with scikit-learn: http://scikit-learn.org/stable/\n",
    "<img src=\"scikit-learn.png\" width=\"800\">\n",
    "\n",
    "This demo is a summarized version of:\n",
    "https://github.com/amueller/scipy-2016-sklearn/blob/master/notebooks/10%20Case%20Study%20-%20Titanic%20Survival.ipynb\n",
    "\n",
    "\n",
    "\n",
    "In this demo we'll see:\n",
    "1. How to do data preprocessing with scikit-learn\n",
    "2. How to use skikit-learn for cross-validation\n",
    "2. How to run all the algorithms we've seen in class (decision tree, perceptron, SVM) with scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the Data\n",
    "\n",
    "## Pre-Installed Datsets\n",
    "\n",
    "Scikit learn has some pre-installed datasets: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n",
    "\n",
    "We're going to check out the \"Iris\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.keys())\n",
    "\n",
    "\n",
    "n_samples, n_features = iris.data.shape\n",
    "print('Number of samples:', n_samples)\n",
    "print('Number of features:', n_features)\n",
    "# the sepal length, sepal width, petal length and petal width of the first sample (first flower)\n",
    "print(iris.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"shape of the features\", iris.data.shape)\n",
    "print(\"shape of the labels\", iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the labels\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use matplotlib to get a scatterplot of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_index = 3\n",
    "y_index = 0\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for label, color in zip(range(len(iris.target_names)), colors):\n",
    "    plt.scatter(iris.data[iris.target==label, x_index], \n",
    "                iris.data[iris.target==label, y_index],\n",
    "                label=iris.target_names[label],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading your own dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv(os.path.join('data', 'titanic.csv'))\n",
    "print(titanic.columns)\n",
    "\n",
    "\n",
    "labels = titanic.survived.values\n",
    "features = titanic[['body', 'sex', 'age', 'parch', 'fare', 'embarked']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Scikit-learn with real world data: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Categorical Values to Numerical Values (Binary Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that pandas dummies are the same as scikit-learn one-hot encoding\n",
    "pd.get_dummies(features).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dummies = pd.get_dummies(features, columns=['parch', 'sex', 'embarked'])\n",
    "features_dummies.head(n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = features_dummies.values\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "imp = Imputer(strategy=\"median\") # can supply different strategies\n",
    "imp.fit(data)\n",
    "train_data = imp.transform(data)\n",
    "\n",
    "\n",
    "print(\"All the training data\", train_data)\n",
    "print(\"Age\", train_data[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "age_data = train_data[:,1]\n",
    "\n",
    "processed_age_data = preprocessing.scale(age_data)\n",
    "\n",
    "print(\"The mean of the original age data is\", age_data.mean(axis=0))\n",
    "print(\"The std  of the original age data is\", age_data.std(axis=0))\n",
    "print()\n",
    "\n",
    "print(\"The mean of the transformed age data is\", processed_age_data.mean(axis=0))\n",
    "print(\"The std  of the transformed age data is\", processed_age_data.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Test-Train Split\n",
    "Still the Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, random_state=0)\n",
    "\n",
    "#Again fill in missing values\n",
    "imp = Imputer()\n",
    "imp.fit(train_data)\n",
    "train_data_finite = imp.transform(train_data)\n",
    "test_data_finite = imp.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms we know in scikit-learn\n",
    "### Most Common Label Classifier\n",
    "\n",
    "Scikit learn calls this a \"dummy\" classifier. Easy \"baseline\" for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier('most_frequent')\n",
    "clf.fit(train_data_finite, train_labels)\n",
    "print(\"Prediction accuracy: %f\" % clf.score(test_data_finite, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "More info at: http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=4000)\n",
    "clf.fit(train_data_finite, train_labels)\n",
    "LinearSVC()\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.score(test_data_finite, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validating SVM\n",
    "From http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [10, 100, 1000, 5000], 'gamma': [1e-4, 1e-5, 1e-6]}]\n",
    "\n",
    "print(\"# Tuning hyper-parameters for accuracy\")\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                   scoring='accuracy')\n",
    "clf.fit(train_data_finite, train_labels)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(random_state=2000)\n",
    "clf.fit(train_data_finite, train_labels)\n",
    "Perceptron(max_iter=1000, tol=0.001)\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.score(test_data_finite, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(train_data_finite, train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(test_data_finite, test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try using a different criterion to build the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(train_data_finite, train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(test_data_finite, test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try limiting the depth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=1)\n",
    "clf.fit(train_data_finite, train_labels)\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "print(\"Accuracy\", clf.score(test_data_finite, test_labels))\n",
    "print(\"The depth of this tree is\", clf.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... what?\n",
    "Let's visualize our tree: http://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.tree_.__getstate__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/tree.html\n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other algorithms we haven't covered in class\n",
    "\n",
    "- Random forests\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Adaboost\n",
    "- Multiclass classifiers\n",
    "- K Nearest Neighbors\n",
    "- Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links!\n",
    "\n",
    "lots of scikit demos: https://github.com/amueller/scipy-2016-sklearn/tree/master/notebooks\n",
    "\n",
    "svm documentation: http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "decision tree documentation: http://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "perceptron documentation: http://scikit-learn.org/stable/modules/linear_model.html#perceptron\n",
    "\n",
    "graphing trees: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "\n",
    "cross-validation parameter search documentation: http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
